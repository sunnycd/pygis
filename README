What is pygis?

A Python 2.5 code library that facilitates the generation of geospatial files ( .shp and .kml ), metadata and format to format conversions. Pygis is developed to interface with ArcGIS 9.3.

    Convert csv to kml (points, polylines, polygons)
    Merge multiple kmls (points, polylines, polygons)
    Convert shapefiles to kml (points and polygons)
    Convert csv to shapefile (points, polylines, polygons)
    Convert kml to shapefile (points and polygons)
    Automate shapefile metadata
    Generate shapefiles from databases (points and polygons)
    Generate file geodatabases (from csv, database)
    Other commonly requested tasks, such as
        Retrieving shapefile data
        Zipping geospatial files
        Converting excel files (.xls, .xlsx) to csv
        Filter csv (get only columns of interest)
        Converting Minutes Degrees Seconds to Decimal Degrees 


Odds and Ends

    This library was built using Python 2.5. NOTE: ArcGIS 9.X hardcodes the Python version.
    Currently, there is only a windows installation because the majority of the functionality in pygis interfaces with ArcGIS which is only available on windows.
    We hope to have an ArcGIS 10 version of this library soon.
        Although not thoroughly tested, this library appears to work on ArcGIS 10 
    If there is some functionality that you want to see and is currently not there, please feel free to submit a ticket and I'll see what I can do. Currently, the library only includes functionalities that were frequently requested.
    If you find a bug, please submit a ticket and I'll fix as soon as I can.
    You may be required to download and install external python libraries. Any required libraries are noted in the examples below. 



Download

pygis-1.0 (released 1-5-2012)  http://gce-lter.marsci.uga.edu/public/app/send_file.asp?accession=software&filename=pygis-1.0.win32.zip

pygis-2.0 (released 1-10-2012)  http://gce-lter.marsci.uga.edu/public/app/send_file.asp?accession=software&filename=pygis-2.0.win32.zip

    Optimizes performance
    Updates 'Csv_To_Shapefile' class
        Adds 'make_shapefile_polygon' method 
    Adds Get_Shapefile_Data class
    Adds kwarg 'cleanup_data' to csv_to_kml
    Adds kwargs 'rows_replace' and 'header_replace' to 'Database_To_Shapefile_Points' and 'Database_To_Shapefile_Polygons' classes 

pygis-2.1 (released 2-9-2012)  http://gce-lter.marsci.uga.edu/public/app/send_file.asp?accession=software&filename=pygis-2.1.win32.zip

    Fixes bug in 'Csv_To_Kml.to_polygon()' and 'Csv_To_Shapefile.make_shapefile_polygon()' method
    Adds 'Csv_To_Shapefile.make_shapefile_polyline()' method 


Dependency Library Downloads

You might be required to install third party libraries

    pyodbc -  http://code.google.com/p/pyodbc/
    numpy -  http://www.lfd.uci.edu/~gohlke/pythonlibs/
    ogr -  http://trac.osgeo.org/gdal/wiki/GdalOgrInPython
    arcgisscripting - Comes installed with ArcGIS installation 


Author

Travis Douce

tdouce (at) uga.edu

travisdouce (at) gmail.com


CSV to KML

Converts csv files to kml files ( points, polylines, polygons )

Dependency libraries: numpy

from pygis.kml.csv_to_kml import Csv_To_Kml

# The location of the csv file
input = r'Path\To\csvfile.csv' 

# Output directory location
output = r'Path\To\output'

# 'cleanup_data' - optional. If passed in and set to True then the csv file will be checked for and clean up'hanging cells'. 'hanging cell'(s) generally are typos where
# a user might inadvertently enter a blank value (i.e. '  ') as the last header or row value.  Although, this is more process intensive it is recommended to set this argument
# to true unless the csv files you are processing were programmaticaly generated. 
a = Csv_To_Kml( input, output, cleanup_data=True )

# Make kml file with polylines
a.to_line()

# Make kml file with points
#a.to_point()

# Make kml file with polygons
#a.to_polygon()



CSV Formatting
Point

The last two columns must be Longitude and Latitude, in this order. The result is one kml with three points 1) Savannah, 2) Tifton, and 3) Valdosta. All column indexes that are NOT '0', the second to last, and the last will be included in the 'information bubble' in Google Earth. An example csv is:

Point,    Description_1,      Description_2,      Description_3,       Longitude, Latitude
Savannah, Description_text_1, Description_text_1, Description_text_3,  -80.826,   32.04
Tifton,   Description_text_2, Description_text_2, Description_text_3,  -81.937,   34.24
Valdosta, Description_text_3, Description_text_3, Description_text_3,  -80.236,   31.65   

Polyline

The last two columns must be Longitude and Latitude, in this order. The result is one kml with three polylines 1) Altamaha, 2) Ogeechee, and 3) St.Mary. NOTE, the description text associated for each row ('Transect' below ) must be the same for every row that has the same 'Transect' value. For instance, for every row that has a 'Transect' value of 'Altamaha', the description text must be the same; 'descrpt text about Altamaha' in this case. This is because you are providing a description for the entire line. All column indexes that are NOT '0', the second to last, and the last will be included in the 'information bubble' in Google Earth. An example csv is:

Transect, description_1,               description_2,          Longitude, Latitude
Altamaha, descrpt text about Altamaha, description_Atlamaha_2, -81.234,   31.345
Altamaha, descrpt text about Altamaha, description_Atlamaha_2, -81.235,   31.346
Altamaha, descrpt text about Altamaha, description_Atlamaha_2, -81.236,   31.347
Altamaha, descrpt text about Altamaha, description_Atlamaha_2, -81.237,   31.348
Ogeechee, descrpt text about Ogeechee, description_Ogeechee_2, -81.244,   31.345
Ogeechee, descrpt text about Ogeechee, description_Ogeechee_2, -81.254,   31.345
Ogeechee, descrpt text about Ogeechee, description_Ogeechee_2, -81.264,   31.346
Ogeechee, descrpt text about Ogeechee, description_Ogeechee_2, -81.274,   31.347
St.Mary,  descrpt text about St.Mary,  description_St.Mary_2,  -81.335,   31.346
St.Mary,  descrpt text about St.Mary,  description_St.Mary_2,  -81.436,   31.347
St.Mary,  descrpt text about St.Mary,  description_St.Mary_2,  -81.537,   31.348

Polygon

The last two columns must be Longitude and Latitude, in this order. The result is one kml with two polygons 1) Polygon_1 and 2) Polygon_2. NOTE, the description text associated for each row ('Transect' below ) must be the same for every row that has the same 'Transect' value. For instance, for every row that has a 'Transect' value of 'Polygon_1', the description text must be the same; 'descrpt text about Polygon_1' in this case. This is because you are providing a description for the entire polygon. All column indexes that are NOT '0', the second to last, and the last will be included in the 'information bubble' in Google Earth. An example csv is:

Transect,  description,                  description_2,                            Longitude, Latitude
Polygon_1, descrpt text about Polygon_1, another description text about Polygon_1, -82.22,    31.46
Polygon_1, descrpt text about Polygon_1, another description text about Polygon_1, -82.09,    31.776
Polygon_1, descrpt text about Polygon_1, another description text about Polygon_1, -81.84,    31.65
Polygon_2, descrpt text about Polygon_2, another description text about Polygon_2, -81.71,    32.08
Polygon_2, descrpt text about Polygon_2, another description text about Polygon_2, -81.02,    31.93
Polygon_2, descrpt text about Polygon_2, another description text about Polygon_2, -81.63,    31.82


Merging KMLs

Merging multiple kml files into one kml file. Kml files of various geometry types (i.e. point, polyline, polygon) can be merged together.

import os, datetime
from pygis.kml.kml_merge import Kml_Merge 

# Path to directory where all the kmls are located
path = r'Path\To\directory_to_kmls\all_kmls'

# The directory where you want the master kml saved
out_folder = r'Path\To_save_merged_kml\output'

# The name of the output master kml
combined_kml_name = 'My_Master_KML'

# make a list of the full paths for each kml in the directory
kmls = [ os.path.join( path, kml ) for kml in os.listdir( path) ]

# 'preserve_styling' - optional. If set to True then all the styling (i.e. colors, markers) will
# be preserved; otherwise all pins will be yellow and polygons and polylines will be white.
# 'append_file_name' - optional. If set to True then the file name will be prepended to each point, polyline or polygon.
# alt_namespaces - optional.  Can pass in a list of xml namespaces to search for. For example: ['http://www.opengis.net/kml/2.2']
master_kml = Kml_Merge( out_folder, combined_kml_name, kmls, preserve_styling=True, append_file_name=True )

# merge the kmls
master_kml.merge()



SHP to KML

Converts shapefile to kml file. Geometry types (i.e. points or polygons) are detected and the analogous kml file is generated and named after the original shapefile. All the fields in the shapefile attribute table are included in the 'information bubble' in Google Earth. Does NOT convert polyline shapefiles.

Dependency libraries: arcgisscripting or ogr and numpy

If ogr is installed it will be used and if it is not then arcgisscripting is used. This makes it possible to convert shapefiles to kmls without having ArcGIS installed.

import os
from pygis.kml.shapefile_to_kml import Shapefile_To_Kml 

# Location to shapefile
shapefile_path = r'Path\To\Shapefile\my_shapefile.shp'

# Path to where you want to the kmls saved
out_folder = r'Path\To\Save\Kmls'

ins = Shapefile_To_Kml( shapefile_path, out_folder )

# Convert to Kml
ins.to_kml()



CSV to SHP
CSV to SHP ( points and polygons )

Converts a csv file to point shapefile. The shapefile is named after the csv file. The csv should be formatted like the csv(s) the section 'CSV To Kml'

Dependency libraries: arcgisscripting, numpy

import os, datetime
from pygis.shapefile.csv_to_shapefile import Csv_To_Shapefile

# Location of csv file 
file_location = r'Path\To\my_csvfile.csv' 

# Location to directory where you want the shapeefiles saved to
out_folder = r'Path\To\output' 

# Coordinate system for shapefiles 
coord_sys = 'C:\\Program Files\\ArcGIS\\Coordinate Systems\\Geographic Coordinate Systems\\World\\WGS 1984.prj'

# Dictionary of of metadata content we want to assign each shapefiles's metadata. This will be viewable in ArcCatalog.
metadata_dict = { 
                 'abstract': '',
                 'purpose':'',
                 'supplementalInfo':'',
                 'orgNameWhoCreatedData':'GCE LTER',
                 'status_progress':'',
                 'publicationDate': str(datetime.date.today()),
                 'status_update':'',
                 'timeperiod_caldate': '',
                 'keyword_theme': [ ],
                 'keyword_place': ['LTER','Sapelo'],
                 'dataUseRestrictions': 'No data use restrictions',
                 'metaDataContact_Org': 'GCE LTER',
                 'metaDataContact_Addr': 'Marine Science Building',
                 'metaDataContact_City': 'Athens',
                 'metaDataContact_State': 'GA',
                 'metaDataContact_Postal': '30602',
                 'metaDataContact_PhoneNum': '999-999-9999',
                 'metaDataContact_Email': 'someone@uga.edu'
               }

# Optional dictionary used to replace values in the header row
header_replace_dict = { 'Latitude' : 'Lat' }

# Optional dictionary used to replace values in all the csv rows (except the header row)
rows_replace_dict = {'text to replace' : 'test', 'Nan' : 'None' }


# Instantiate. This method makes sure that csv headers, which will become the 
# attribute table headers in ArcGIS, satisfy the ArcGIS requirements for attribute table field names, such as
# csv headers/attribute table names can not be longer than 10 characters, etc (See http://support.esri.com/en/knowledgebase/techarticles/detail/23087). 
# 'header_replace' - optional.  Allows you to pass in a dictionary of alternative header names. Key = csv header name and Value = the alternative csv header name.
# This allows you to control how the header names are truncated rather than relying on the default, in the case they do not satisfy ArcGIS requirements.
# 'rows_replace' - optional. Allows you to pass in a dictionary to replace any table rows values in the entire csv file (except for the header row). 
# 'cleanup_data' - optional. If passed in and set to True then the csv file will be checked for and clean up 'hanging cells'. 'hanging cell' generally are typos where
# a user might enter a blank value (i.e. '  ') as the last header or row value.  Although, this is more process intensive it is recommended to set this argument
# to true unless the csv files you are processing were programmaticaly generated. 
file_inst = Csv_To_Shapefile( file_location, out_folder, coord_sys, rows_replace=rows_replace_dict, header_replace=header_replace_dict, cleanup_data=True )

# Invoke the 'make_shapefile' method.  
# 'deep_data_type' - optional. Inspects all columns (the entire column) to determine
# the appropriate datatype for the field that will be created for it in the ArcGIS attribute table.
#file_inst.make_shapefile_point( deep_data_type=True )
#file_inst.make_shapefile_polyline( deep_data_type=True )
file_inst.make_shapefile_polygon( deep_data_type=True )

# Invoke the 'make_metadata' method. Write metadata for shapefile
file_inst.make_metadata( metadata_dict )



CSV to File Geodatabase (points and polygons)

Creates a filegeodatabase and adds a directory of csv files to the filegeodatabase as featureclasses. The csv formatting is the same as for 'CSV to SHP' section. All the kwargs that are available in CSV To SHP are available.

Dependency libraries: arcgisscripting, numpy

import os
from pygis.shapefile.csv_to_shapefile_points import Csv_To_Shapefile_Points
from pygis.shapefile.shapefile_utilities import File_Geodatabase 

# Location of directory of csv files 
files_location = r'Path\To\csvFiles' 

# Name of the filegeodatabase
fgb_name = 'My_filegeodatabase.gdb'

# Location to directory where you want the file geodatabase saved to
out_folder = r'Path\To\output' 

# Coordinate system for shapefiles 
coord_sys = 'C:\\Program Files\\ArcGIS\\Coordinate Systems\\Geographic Coordinate Systems\\World\\WGS 1984.prj'

# Invoke the the 'File_Geodatabase' class
a = File_Geodatabase( fgb_name , out_folder )

# Create the filegeodatabase
a.make_filegeodatabase()

# Loop through each csv file 
for csvFile in os.listdir( files_location ):

    # Build the pathway to the csv file so it can be opened
    file_location = os.path.join( file_location, csvFile )
   
    # Instantiate 'Csv_To_Shapefile_Points' object. The optional argument 'fileGDB' has to be set to 'fgb_name'
    file_inst = Csv_To_Shapefile( file_location, out_folder, coord_sys, cleanup_data=True, fileGDB=fgb_name )

    # Invoke the 'make_shapefile' method. Add featureclass to filegeodatabse  
    # file_inst.make_shapefile_point()

    file_inst.make_shapefile_polygon()



Database to SHP

Generates shapefiles from data stored in a database. In order to use this class, the database table\view HAS to be set up as described below. Realizing that all the data sets' information are most likely stored in numerous tables it is advised to make a 'view' or 'table' containing all the combined data. If you are interested in automating metadata specific to each shapefile, then generate shapefiles one at at time and uniquely populate the metadata dict. You can also generate filegeodatabases ( See section 'CSV to File Geodatabase' ).
Database to SHP ( Points )

Generates a shapefile that contains one or many points

Dependency libraries: arcgisscripting, pyodbc, numpy

from pygis.shapefile.database_to_shapefile_points import Database_To_Shapefile_Points
from pygis.shapefile.shapefile_utilities import zip_it

# DATABASE CONNECTION: See http://code.google.com/p/pyodbc/wiki/GettingStarted for
# more database connection information and options
database_cnxn = 'DSN=??????;UID=????????;PWD=??????'

# DATABASE TABLE NAME: Database table name you are retreiving data from
# It should be something like:
database_table = 'dbo.somedatatable'

# OUTPUTPATH: The path to output folder (i.e. where you want the data saved to)
# This will be unique for every user (most likely). It should be something like:
out_folder = 'Path\To\OutFolder'

# COORDINATE SYSTEM: Path to the coordinate system you want the shapefiles to be projected in.
coord_sys = 'C:\\Program Files\\ArcGIS\\Coordinate Systems\\Geographic Coordinate Systems\\World\\WGS 1984.prj'

# SHAPEFILE COLUMN NAME:
# The column name that holds the rows that you want make shapefiles for.
shapefile_column_name = 'Accession'

# SHAPEFILE NAMES:
# Rows from the database table column.  A shapefile will be created for and named
# after: 1) Each distinct row if the an empty list is passed in. So, if you want to make 
# a shapefile for every distinct row in the database table column, then pass in 
# an empty list, for example: [] ; OR 2) Each item  in the list if the there 
# are items in the list. So,  If you want shapefiles for only select rows, then put the row values in a list  
indv_query_shapefile_name = ['NUT-GCEM-0210', 'PLT-GCET-0608' ]

# POINT DECIDER:
# Column name from the database table(ONLY ONE ITEM IS ALLOWED IN THIS LIST).
# For each shapefile (as determined in 'SHAPEFILE NAME'), a point will be created for each  row in this database table column. 
point_decider_column = ['SiteCode']

# SQL QUERY/GIS ATTRIBUTE TABLE FIELDS:
# Column names from the database table that are to be included in the sql query.
# If there are no more column names to be included, type 'none' (in single quotes). This list (along with the
# previous question's entry) will be included in the 'select' sql clause.  Also, an 'attribute table field' (in ArcGIS)
# will be created for each item in this list.
querying_columns = ['Location','DateStart','DateEnd','Latitude','Longitude','DataSetID','Descr']

# LATITUDE:
# The exact spelling of the column name that holds the latitude coordinates
latitude = 'Latitude'

# LONGITUDE:
# The exact spelling of the column name that holds the longitude coordinates
longitude = 'Longitude'

# This is a dictionary that has the values and key pairs for data that you want
# inserted into ALL the xml metadata files.  The dictionary keys HAVE to make
# exactly the methods in 'Esri_metadata' class in 'pygis.shapefiles.metadata
metadata_dict = {
                'abstract': 'This is an abstract that I just added',
                'purpose': 'This is my purpose'
               }

# Dictionary to replace row values with (i.e. any value in the entire database result for a shapefile, except for 'querys'
rows_replace_dict = { '' : 'None' }

# Dictionary to replace header values with (i.e. querys and what will appear in attribute table header column) 
header_replace_dict = { 'SiteCode' : 'Site' }

ins = Database_To_Shapefile_Points()

# Pass in variables
# suffix - optional.  Allows you to append a suffix to the shapefile name. For example: suffix='_testing'
# rows_replace - optional.  Allows you to replace values for the entire shapfile except for shapefile name and querys/attribute headers.
# header_replace - optional.  Allows you to replace values in querys/attribute headers.
ins.make_shapefile( database_cnxn, database_table, shapefile_column_name,
                    indv_query_shapefile_name, point_decider_column, querying_columns, latitude, longitude,
                    coord_sys,  out_folder, metadata_dict, suffix='_blah', rows_replace=rows_replace_dict, header_replace=header_replace_dict )

# Allows you replace all non-permitted characters that were in the filename with ONE character
ins.putBackLegals( out_folder, '-')


Datbase to SHP ( Points ) - Database Table/View Formatting

Consider the following data base structure:

Accession       Description           SiteCode     Longitude   Latitude
NUT-GCEM-0210   Some description_1    ALT-BASIN    -81.4356    31.5256 
NUT-GCEM-0210   Some description_2    ALT-BASIN    -81.2356    31.1256 
NUT-GCEM-0210   Some description_3    ALT-BASIN    -81.62356   31.3256 
PLT-GCET-0608   Some description_1    CentralCst   -81.7468    31.980  
PLT-GCET-0608   Some description_1    CentralCst   -81.7468    31.980  
HYD-GCES-0508b  Some description_1    CentralCst   -81.7834    31.8778

This script would output the following:

1) If the variable 'IndvQueryShapefileName' was passed in as an empty list,
   and 'SiteCode' was passed in as 'polygonDeciderColumn', then
   the 3 Shapefiles would be created, 'NUT-GCEM-0210' (3 points), 
   'PLT-GCET-0608' (2 points in shapefile), and  'HYD-GCES-0508b' (1 point). 

2) If the variable 'IndvQueryShapefileName' was passed in with items in the
   list (such as 'NUT-GCEM-0210' and 'HYD-GCES-0508b'), then two shapefiles
   would be created,'NUT-GCEM-0210'(3 points) and 'HYD-GCES-0508b'(1 point in shapefile)


Database to SHP ( Polygons )

Generates a shapefile that contains many polygons

Dependency libraries: arcgisscripting, pyodbc, numpy

import datetime
from pygis.shapefile.database_to_shapefile_polygons import Database_To_Shapefile_Polygons 
from pygis.shapefile.shapefile_utilities import zip_it

# DATABASE CONNECTION: See http://code.google.com/p/pyodbc/wiki/GettingStarted for
# more database connection information and options. It should be something like:
database_cnxn = 'DSN=???????;UID=???????;PWD=??????'

# DATABASE TABLE NAME: Database table name you are retreiving data from
database_table = 'dbo.somedatatable'
                
# OUTPUTPATH: The path to output folder (i.e. where you want the data saved to)
# This will be unique for every user (most likely). It should be something like:
out_folder = r'Path\To\outfolder'

# COORDINATE SYSTEM: Path to the coordinate system you want the shapefiles to be projected in.
coord_sys = 'C:\\Program Files\\ArcGIS\\Coordinate Systems\\Geographic Coordinate Systems\\World\\WGS 1984.prj'

# SHAPEFILE NAME COLUMN: The column name that holds the shapefile names. This
# is the name of the column that holds the items in the list  'IndvQueryShapefileName'.
shapefile_column_name = 'Accession'

# SHAPEFILE NAMES/ SQL QUERY:  This is what will be the shapefile name.  Items in this list must be present the the column 
# named in the variable 'shapefileColumnName'. A shapefile will be created for each item in this list. If you want to create 
# a shapefile for every distinct item in the column leave the an empty list.
indv_query_shapefile_name = ['NUT-GCEM-0206','INV-GCEM-0209']

# Feature DECIDER: The name of the column that holds the names of the features
# that will be included in the shapefile. A feature will be created for each
# distinct row in this column for each item in 'IndvQueryShapefileName'. ONLY ONE ITEM
# IS ALLOWED IN THIS LIST).
polygonDeciderColumn = ['SiteCode']

# SQL QUERY/GIS ATTRIBUTE TABLE FIELD NAMES: Column names from the database table/view 
# that are to be included in the sql query, and subsequently as the column
# headers in the ArcGIS attribute table. It there are no more querys/gis attribute table names to
# be added leave the list empty, for example: queryingColumns = [].
querying_columns = ['SiteName','SiteCode','Hectares','Ownership','Vegtation','SiteLoc','SiteType']

# Column name from database where the Latitude coordinates are located
latitude = 'Latitude'

# Column name from database where the Longitude coordinates are located
longitude = 'Longitude'

# Dictionary of of metadata content we want to assign each shapefiles's
# metadata. This will be viewable in ArcCatalog
metadata_dict = { 
                 'abstract': '',
                 'purpose':'',
                 'supplementalInfo':'',
                 'orgNameWhoCreatedData':'GCE LTER',
                 'status_progress':'',
                 'publicationDate': str(datetime.date.today()),
                 'status_update':'',
                 'timeperiod_caldate': '',
                 'keyword_theme': [ ],
                 'keyword_place': ['LTER','Sapelo'],
                 'dataUseRestrictions': 'No data use restrictions',
                 'metaDataContact_Org': 'GCE LTER',
                 'metaDataContact_Addr': 'Marine Science Building',
                 'metaDataContact_City': 'Athens',
                 'metaDataContact_State': 'GA',
                 'metaDataContact_Postal': '30602',
                 'metaDataContact_PhoneNum': '999-999-9999',
                 'metaDataContact_Email': 'someone@uga.edu'
               }

# Dictionary to replace row values with (i.e. any value in the entire database result for a shapefile, except for 'querys'
rows_replace_dict = { '' : 'None' }

# Dictionary to replace header values with (i.e. querys and what will appear in attribute table header column) 
header_replace_dict = { 'SiteCode' : 'Site' }

a = Database_To_Shapefile_Polygons()

# Invoke the method and pass in all the arguments
# rows_replace - optional.  Allows you to replace values for the entire shapfile except for shapefile name and querys/attribute headers.
# header_replace - optional.  Allows you to replace values in querys/attribute headers.
a.make_shapefile( database_cnxn, database_table, shapefile_column_name,
                  indv_query_shapefile_name, point_decider_column, querying_columns, latitude, longitude,
                  coord_sys,  out_folder, metadata_dict, suffix='_blah', rows_replace=rows_replace_dict, header_replace=header_replace_dict )

# Allows you replace all non-permitted characters that were in the filename with ONE character
ins.putBackLegals( out_folder, '-')


Datbase to SHP ( Polygons ) - Database Table/View Formatting

Accession       Description           SiteCode     Longitude   Latitude
NUT-GCEM-0210   Some description_1    ALT-BASIN    -81.4356    31.5256 
NUT-GCEM-0210   Some description_1    ALT-BASIN    -81.2356    31.1256 
NUT-GCEM-0210   Some description_1    ALT-BASIN    -81.62356   31.3256 
NUT-GCEM-0210   Some description_1    CST-TRFGC    -81.4356    31.5256 
NUT-GCEM-0210   Some description_2    CST-TRFGC    -81.2356    31.1256 
NUT-GCEM-0210   Some description_2    CST-TRFGC    -81.62356   31.3256 
PLT-GCET-0608   Some description_1    CentralCst   -81.7468    31.980  
PLT-GCET-0608   Some description_1    CentralCst   -81.2468    31.980  
PLT-GCET-0608   Some description_1    CentralCst   -81.6468    31.980  

This script would output the following:

1) If the variable 'IndvQueryShapefileName' was passed in as an empty list, 
   and 'SiteCode' was passed in as 'polygonDeciderColumn', then 2 Shapefiles would 
   be created, NUT-GCEM-0210 (2 polygons in shapefile), PLT-GCET-0608 (1 polygons in shapefile)

2) If the variable 'IndvQueryShapefileName' was passed in with items in the
   list (such as 'NUT-GCEM-0210' ), then one shapefile would be created,'NUT-GCEM-0210'(2 polygons in shapefile)


Database to filegeodatabase ( Points and Polygons )

Generates a filegeodatabase that contains one or many featureclasses. The database table/view setup is the same as for the "Database to Shapefiles ( Points ). NOTE: The code does not currently support the generation of metadata for filegeodatabases or featureclasses.

Dependency libraries: arcgisscripting, pyodbc, numpy

from pygis.shapefile.database_to_shapefile_points import Database_To_Shapefile_Points
from pygis.shapefile.shapefile_utilities import File_Geodatabase

# Set up same variables as 'Database to Shapefile ( Points )' and/or 'Database to Shapefile ( Polygons )'

# DATABASE CONNECTION: See http://code.google.com/p/pyodbc/wiki/GettingStarted for
# more database connection information and options. It should be something like:
database_cnxn = 'DSN=???????;UID=???????;PWD=??????'
# ...
# ...
# ...

# File geodatabase name
filegdb_name = 'test_file.gdb'

# Invoke the the 'File_Geodatabase' class
fgdb = File_Geodatabase( filegdb_name , outFolder )

# Create the filegeodatabase
fgdb.make_filegeodatabase()

ins = Database_To_Shapefile_Points()

# fileGDB - required for the generation of filegeodatabases.  This is the name of the filegeodatabase
a.make_shapefile( database_cnxn, database_table, shapefile_column_name,
                  indv_query_shapefile_name, point_decider_column, querying_columns, latitude, longitude,
                  coord_sys,  out_folder, metadata_dict, fileGDB=filegdb_name )

# If you want to add polygon featureclasses to the same file geodatabase then invoke the 'Database_To_Shapefile_Polygons' class
# and add the kwarg 'fileGDB=filegdb_name' (i.e. the same filegeodbase as above)
# ins = Database_To_Shapefile_Polygons()
#a.make_shapefile( database_cnxn, database_table, shapefile_column_name,
                  indv_query_shapefile_name, point_decider_column, querying_columns, latitude, longitude,
                  coord_sys,  out_folder, metadata_dict, fileGDB=filegdb_name )



KML to SHP

Dependency libraries: arcgisscripting, pyodbc

Generates a shapfile from a kml. A kml might have multiple geometry types (points and polygons), so this script automatically generates a shapefile for each geometry type, with the geometry type appended to the file name. This does NOT work for polylines.

from pygis.shapefile.kml_to_shapefile import Kml_To_Shapefile
from pygis.shapefile.shapefile_utilities import zip_it

# Path to the kml you are working on
kml_path = r'Path\To\MyKml.kml'

# Path to the directory where you want the shapefile to be saved
out_folder = r'Path\To\Output'

# Path to the coordinate system you want the shapefiles to be projected in.
coord_sys = r'C:\Program Files\ArcGIS\\Coordinate Systems\Geographic Coordinate Systems\World\WGS 1984.prj'

# This is a dictionary that has the values and key pairs for data that you want
# inserted into ALL the xml metadata files.  The dictionary keys HAVE to make
# exactly the methods in 'Esri_metadata' class in 'pygis.shapefiles.metadata
metadata_dict = {
                'abstract': 'This is an abstract that I just added',
                'purpose': 'This is my purpose'
               }

ins = Kml_To_Shapefile( kml_path, out_folder, coord_sys, metadata_dict )

# Invoke an attribute. This is a list of texts that were appended to the
# shapefile, which corresponds to the geometry types found in the shapefile 
kml_geometrys = ins.geomTracker

# Call the zip_it method and zip all the files in the directory.
# The 'descrip' argument is applies the text to the end of each zip file.
# The 'ignore_geometry' argument is a list that tells the script to package up
# any shapefiles with the same basename (ignoring any geometry type appending
# added by the 'Kml_To_Shapefile' class), so that all related shapefiles will be
# packaged in a common zipfile.
zip_it( out_folder, descrip='_Aug_3_2011', ignore_geometry=kml_geometrys )



Generating Metadata ( to already existing shapefiles )

from pygis.shapefile.metadata import make_shapefile_metadata

# Dictionary of of metadata content we want to assign a shapefiles's
# metadata. This will be viewable in ArcCatalog. The dictionary keys have to be
# spelled EXACTLY as they are here!  You can leave out dictionary keys if you do
# want that particular section to show up in the metadata.
metadata_dict = { 
                'abstract': 'This is my abstract',
                'purpose': 'This is my purpose',
                'supplementalInfo':'',
                'orgNameWhoCreatedData':'Georgia Coastal Ecosystems Long Term Ecological Research',
                'status_progress':'Completed',
                'publicationDate': '09-08-2011',
                'status_update':'updated',
                'timeperiod_caldate': '',
                'keyword_theme': ['Marsh' , 'Beach', 'Ecology' ],
                'keyword_place': ['LTER','Sapelo Island Georgia'],
                'dataUseRestrictions': 'No data use restrictions',
                'metaDataContact_Org': 'Georgia Coastal Ecosystems Long Term Ecological Research',
                'metaDataContact_Addr': 'Marine Science Building',
                'metaDataContact_City': 'Athens',
                'metaDataContact_State': 'GA',
                'metaDataContact_Postal': '30602',
                'metaDataContact_PhoneNum': '999-999-9999',
                'metaDataContact_Email': 'someone@uga.edu'
              }

# Path to xml file (used to populate metadata in ArcCatalog) for shapefile
make_shapefile_metadata( r'Path\shapefile.shp.xml', metadata_dict )



General


Retrieving SHP Data

Retrieves shapefile data for points or polygons. NOTE: This will not work for polygon shapefiles that have an inner circle (i.e. a polygon that resembles the shape of a doughnut)

Dependency libraries: arcgisscripting or ogr

from pygis.shapefile.get_shapefile_data import Shapefile_Data

shapefile_path = r'Path\To\Shapefile\my_shapefile.shp'

ins = Shapefile_Data( shapefile_path )

ins.get()

print 'filename: ', ins.fileName
print 'geometry type: ', ins.geomType
print '# of features: ', ins.featureCount
print 'vertices: ', ins.vertices
print 'feature values: ', ins.attributeRowData
print 'attribute table columns: ', ins.attributeColumns


Zipping geospatial files

Puts geospatial files(shapefiles and kml) in a zip file. If there are already .zip or .gdb files in the outFolder then these will be left alone. For example, if there were 5 shapefiles (each shapefile has 5 or so associated files) in the outFolder then each shapefile (all the associated files) are put into a unique zip file named after the shapefile. The result is 5 unique zip files.

from pygis.shapefile.shapefile_utilities import zip_it

out_folder = r'Path\To\geospatial_files'

# descrip - optional.  Will append text to zip file only
# zip_it( out_folder, descrip='_Aug_03_2011' )

# ignore_geometry - optional.  Will ignore the specified part of the associated shapefiles when zipping.
# This will most likely be used if you are using this library to convert kml to shapefiles and zipping them.
# For example: If you had two shapefiles 'Shapefile_Polygon' and 'Shapefile_Point', and you passed in 
# '['_Polygon', '_Point' ]' then both of these shapefiles will be contained in a zip file named 'Shapefile.zip'
# zip_it( out_folder, ignore_geometry=['_Polygon','_Point'] )

zip_it()


Converting Degrees Minutes Seconds to Decimal Degrees

Converts a csv that contains degrees minutes seconds to decimal degrees

from pygis.utilities.utilities import dms_to_dd

# Path to csv file that contains the data you want to process
path_to_input = r'Path\to\to_dd.csv'

# Path to where you want to save the csv file
path_to_output = r'Path\to\output'

# lat_index - optional. The column index that contains the latitude coordinates
# long_index - optional. The column index that contains the longitude coordinates
dms_to_dd( path_to_input, path_to_output, lat_index=2, long_index=3 )

# If you do not specifiy the latitude and longitude index like above, then the csv
# can ONLY have two columns, a latitude and longitude column, in that order
# dms_to_dd( path_to_input, path_to_output )

CSV Formatting
Input csv file format

Only positive degrees are allowed. (The negative value is expressed with the 'S' and 'W' character)

Column_1,    Column_2,    Latitude,        Longitude
some text_1, some text_2, 32°2' 24.6474"S, 80°49' 42.9594"E
some text_1, some text_2, 32°2' 21.0114"N, 80°50' 21.264"W
some text_1, some text_2, 32°2' 17.988"N,  80°50' 59.9994"W

Output csv file format

Latitude,    Longitude
-32.04017983, 80.82859983
32.03916983, -80.83924
32.03833,    -80.84999983
32.03732983, -80.86079983


Filter CSV By Columns

Filter a csv file by column and create a new csv file that only contains the columns of interest. This can be useful if you are processing many csv files to shapefile or kml and you only want a few of the columns (rather than all of them) to show up in the final file format.

from pygis.utilities.utilities import filter_csv 

path_to_input = r'Path\To\myfile.csv'
path_to_output = r'Path\To\output'

headers_of_interest = [ 'Transect', 'description', 'Latitude', 'Longitude' ]

# 'replace_errors' - optional. Text to replace text that occurs in row values that would otherwise cause the script to crash, such as [ '\n' , '"' , "'" , ',' ]
filter_csv( path_to_input, path_to_output, headers_of_interest, replace_errors=' -xxxxx- ' )

# filter_csv( path_to_input, path_to_output, headers_of_interest )

CSV Formatting
Input csv file format

Transect,	description,	description_2,	        do_not_want,	        Longitude,	Latitude
Savannah,	SV-02,	        Sav_description_2,	do not want text,	-82.22,	        31.46
Savannah,	SV-02,	        Sav_description_2,	do not want text,	-82.09,	        31.776
Savannah,	SV-02,	        Sav_description_2,	do not want text,	-81.84,	        31.65
Ogeechee,	OG-02,	        Ogee_description_2,	do not want text,	-81.71,	        32.08
Ogeechee,	OG-02,	        Ogee_description_2,	do not want text,	-81.02039,	31.93
Ogeechee,	OG-02,	        Ogee_description_2,	do not want text,	-81.63,	        31.82083

Output csv file format

Transect,	description,	Longitude,	Latitude
Savannah,	SV-02,	        -82.22,	        31.46
Savannah,	SV-02,	        -82.09,	        31.776
Savannah,	SV-02,	        -81.84,	        31.65
Ogeechee,	OG-02,	        -81.71,	        32.08
Ogeechee,	OG-02,	        -81.02039,	31.93
Ogeechee,	OG-02,	        -81.63,	        31.82083


Convert XLS and XLSX to CSV

Converts .xls and .xlsx Microsoft excel files to csv files. There is an option to recursively covert excel files from a root directory.

Dependency libraries: openpyxl, xlrd

*** Warning xlrd gives a memory leak warning although it does not appear to corrput the data (at least the quantity of data I've processed)

from pygis.utilities.utilities import excel_to_csv, xls_to_csv, xlsx_to_csv

# Path to where you want the csv file(s) saved
path_to_output_directory = r'Path\To\output'

# Path to root directory if you want to recursively convert excel files to csv files in a directory
path_to_root_directory = r'Path\To\Root\excel_to_csv'

# Recursively convert excel files to csv in a directory tree
# excel_to_csv( path_to_root_directory, path_to_output_directory )

# path_to_input_directory = r'C:\Path\To\File\forPoints.xls'
# xls_to_csv( path_to_input_directory, path_to_output_directory )

# path_to_input_directory = r'C:\Path\To\File\test.xlsx'
# xlsx_to_csv( path_to_input_directory, path_to_output_directory )


GCE Webservice

Calls a Georgia Coastal Ecosystems webservice that generates csv files. Contact author to get a list of possible web service calls.

from pygis.utilities.utilities import gce_webservice 

base_url = 'http://xxxx.uga.edu'
delimiter = '&'
path_to_output = r'Path\to\output'

gce_webservice( base_url, path_to_output, type='sonde', name='GCE10', shapefile='yes' )

